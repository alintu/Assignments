{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE\n",
    "#i run this code in csc virtual enfironment\n",
    "#so it may require some preparartion steps (i.e. with files upload) that are described below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mxnet==1.5.1\n",
      "  Downloading mxnet-1.5.1-py2.py3-none-manylinux1_x86_64.whl (23.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.1 MB 2.7 MB/s eta 0:00:01/s eta 0:00:08█████████▋                      | 7.0 MB 2.7 MB/s eta 0:00:07�██████████▊                | 11.3 MB 2.7 MB/s eta 0:00:0515.8 MB 2.7 MB/s eta 0:00:03��███▍    | 19.8 MB 2.7 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /opt/conda/lib/python3.7/site-packages (from mxnet==1.5.1) (1.18.2)\n",
      "Collecting graphviz<0.9.0,>=0.8.1\n",
      "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /opt/conda/lib/python3.7/site-packages (from mxnet==1.5.1) (2.23.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet==1.5.1) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet==1.5.1) (1.25.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet==1.5.1) (2019.11.28)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet==1.5.1) (3.0.4)\n",
      "Installing collected packages: graphviz, mxnet\n",
      "  Attempting uninstall: graphviz\n",
      "    Found existing installation: graphviz 0.13.2\n",
      "    Uninstalling graphviz-0.13.2:\n",
      "      Successfully uninstalled graphviz-0.13.2\n",
      "Successfully installed graphviz-0.8.4 mxnet-1.5.1\n"
     ]
    }
   ],
   "source": [
    "! pip install mxnet==1.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.4.58-cp37-cp37m-manylinux2014_x86_64.whl (60.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 60.3 MB 187 kB/s eta 0:00:01    |██▍                             | 4.5 MB 4.2 MB/s eta 0:00:14                     | 9.4 MB 4.2 MB/s eta 0:00:13 MB 4.2 MB/s eta 0:00:11��████▍                     | 19.6 MB 4.2 MB/s eta 0:00:10          | 27.8 MB 4.2 MB/s eta 0:00:0832.2 MB 4.2 MB/s eta 0:00:07MB/s eta 0:00:06��        | 45.3 MB 4.2 MB/s eta 0:00:04MB/s eta 0:00:03��█████████████████████████▎  | 55.1 MB 4.2 MB/s eta 0:00:02�██▋| 59.6 MB 4.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from opencv-python) (1.18.2)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.4.58\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (2.23.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (3.2.1)\n",
      "Collecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.5.4.58-cp37-cp37m-manylinux2014_x86_64.whl (47.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 47.6 MB 2.1 MB/s eta 0:00:01              | 1.4 MB 2.1 MB/s eta 0:00:2221███▋                          | 8.3 MB 2.1 MB/s eta 0:00:19█████████                       | 13.3 MB 2.1 MB/s eta 0:00:17██▌                   | 18.7 MB 2.1 MB/s eta 0:00:14�██████████▋                | 23.2 MB 2.1 MB/s eta 0:00:12MB/s eta 0:00:09ta 0:00:07███████████████████████▊      | 38.3 MB 2.1 MB/s eta 0:00:05███████▏  | 43.4 MB 2.1 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests) (2019.11.28)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests) (1.25.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.18.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.14.0)\n",
      "Installing collected packages: opencv-python-headless\n",
      "Successfully installed opencv-python-headless-4.5.4.58\n"
     ]
    }
   ],
   "source": [
    "! pip install requests matplotlib opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mxnet as mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=Warning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1 (5 points):\n",
    "\n",
    "go to https://github.com/miaow1988/SqueezeNet_v1.2 and download the 'symbol.json' and '.params' files (there is not a 'synset.txt' file! so don't use these lines, Hint: just comment these lines).\n",
    "\n",
    "* Install MXNet v1.5 (hint: create a new conda environmet with python 3, pip install mxnet==1.5.1) and follow the same steps of the lecture (part: *Using pre-trained models as feature extractors*). Find the flatten output layer and create a feature extractor (hint: It should be a numpy array of 1000 elements).\n",
    "* Download the dogs versus cats *training folder* from https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data (Remember the number of images is 12500 for each class).\n",
    "* Extract the array of features for different number of images (N: 10, 100, 500, 1000, also 5000 and 12500) and for each value train your favorite binary classifier (only one!!!) using GridSearch to optimize some hyperparameters. Consider to use https://notebooks.csc.fi if you have computational limitations. \n",
    "\n",
    "* Report the accuracy for each value of N and the computational time during the training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model-symbol.json', 'model-0000.params']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path='https://github.com/miaow1988/SqueezeNet_v1.2/'\n",
    "[mx.test_utils.download(path+'raw/master/model-symbol.json'),\n",
    " mx.test_utils.download(path+'raw/master/model-0000.params')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym, arg_params, aux_params = mx.model.load_checkpoint('model', 0)\n",
    "mod = mx.mod.Module(symbol=sym, context=mx.cpu(), label_names=None)\n",
    "mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))], \n",
    "         label_shapes=mod._label_shapes)\n",
    "mod.set_params(arg_params, aux_params, allow_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fire9_concat_output',\n",
       " 'dropout0_output',\n",
       " 'conv10_conv_weight',\n",
       " 'conv10_conv_bias',\n",
       " 'conv10_conv_output',\n",
       " 'conv10_relu_output',\n",
       " 'pool10_output',\n",
       " 'flatten0_output',\n",
       " 'softmax_label',\n",
       " 'softmax_output']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the last 10 layers\n",
    "all_layers = sym.get_internals()\n",
    "all_layers.list_outputs()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_sym = all_layers['flatten0_output']\n",
    "fe_mod = mx.mod.Module(symbol=fe_sym, context=mx.cpu(), label_names=None)\n",
    "fe_mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))])\n",
    "fe_mod.set_params(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(img):\n",
    "    fe_mod.forward(Batch([mx.nd.array(img)]))\n",
    "    features = fe_mod.get_outputs()[0].asnumpy()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from subprocess import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting slugify\n",
      "  Downloading slugify-0.0.1.tar.gz (1.2 kB)\n",
      "Building wheels for collected packages: slugify\n",
      "  Building wheel for slugify (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for slugify: filename=slugify-0.0.1-py3-none-any.whl size=1908 sha256=04bc3e7b2df5357107557a4d9ca778be04639fc286a5e8d9df95e2c493db4eb9\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/d4/7b/0d/bd65011a1b442843bb4043e396f727ab0f1e76050355b9156a\n",
      "Successfully built slugify\n",
      "Installing collected packages: slugify\n",
      "Successfully installed slugify-0.0.1\n"
     ]
    }
   ],
   "source": [
    "! pip install slugify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "runtime 15 sec\n"
     ]
    }
   ],
   "source": [
    "#upload kaggle.json file beforehand\n",
    "start = time()\n",
    "script = f'''\n",
    "    pip install --upgrade --force-reinstall --no-deps kaggle;\n",
    "    mkdir -p ~/.kaggle;\n",
    "    cp ~/kaggle.json ~/.kaggle/;\n",
    "    chmod 600 ~/.kaggle/kaggle.json;\n",
    "    kaggle competitions download --quiet -c dogs-vs-cats-redux-kernels-edition;\n",
    "    unzip -o dogs-vs-cats-redux-kernels-edition.zip;\n",
    "    unzip -o train.zip;\n",
    "    '''\n",
    "proc = run(script,\n",
    "          shell=True,\n",
    "          text=True,\n",
    "          capture_output=True,\n",
    "          timeout=120)\n",
    "print(proc.stderr)\n",
    "print(f'runtime {time()-start:.0f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Batch = namedtuple('Batch', ['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "\n",
    "mypath = join(os.getcwd(),'train')\n",
    "\n",
    "cats_imgs = [join(mypath,f) for f in listdir(mypath) if f.startswith('cat')]\n",
    "dogs_imgs = [join(mypath,f) for f in listdir(mypath) if f.startswith('dog')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def get_image(url, show=False):\n",
    "    if url.startswith('http'):\n",
    "        # download and show the image\n",
    "        fname = mx.test_utils.download(url)\n",
    "    else:\n",
    "        fname = url\n",
    "    img = cv2.cvtColor(cv2.imread(fname), cv2.COLOR_BGR2RGB)\n",
    "    if img is None:\n",
    "         return None\n",
    "    if show:\n",
    "         plt.imshow(img)\n",
    "         plt.axis('off')\n",
    "    # convert into format (batch, RGB, width, height)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = np.swapaxes(img, 0, 2)\n",
    "    img = np.swapaxes(img, 1, 2)\n",
    "    img = img[np.newaxis, :]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with N = 10 , number of features\n",
    "\n",
    "Nmax = 10\n",
    "cats_features = [get_features(get_image(img)).ravel() for img in cats_imgs[:Nmax]]\n",
    "dogs_features = [get_features(get_image(img)).ravel() for img in dogs_imgs[:Nmax]]\n",
    "\n",
    "Y_cats = np.array(Nmax * [1])\n",
    "Y_dogs = np.array(Nmax * [0])\n",
    "\n",
    "X_cvd = np.vstack([cats_features,dogs_features])\n",
    "Y_cvd = np.vstack([Y_cats,Y_dogs]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use favourite classifier model\n",
    "#LogisticRegression?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 1.00\n",
      "Best parameters: {'C': 1, 'multi_class': 'multinomial', 'solver': 'sag', 'tol': 0.1}\n",
      "Best cross-validation score: 1.00\n",
      "\n",
      "Best estimator:\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=3000,\n",
      "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='sag', tol=0.1, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#finding best parameters for classifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'tol': [0.0001,0.001,0.01,0.1,1],\n",
    "              'C': [0.1,1,10,50],\n",
    "              'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "              'multi_class': ['auto', 'ovr', 'multinomial']}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=3000), param_grid, cv=5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cvd, Y_cvd, random_state=42)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Test set score: {:.2f}\".format(grid_search.score(X_test, y_test)))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\\n\".format(grid_search.best_score_))\n",
    "print(\"Best estimator:\\n{}\".format(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 features:\n",
      "runtime 0 seconds\n",
      "test set score: 1.00\n",
      "--------------------\n",
      "100 features:\n",
      "runtime 4 seconds\n",
      "test set score: 0.94\n",
      "--------------------\n",
      "500 features:\n",
      "runtime 17 seconds\n",
      "test set score: 0.90\n",
      "--------------------\n",
      "1000 features:\n",
      "runtime 35 seconds\n",
      "test set score: 0.95\n",
      "--------------------\n",
      "5000 features:\n",
      "runtime 171 seconds\n",
      "test set score: 0.96\n",
      "--------------------\n",
      "12500 features:\n",
      "runtime 431 seconds\n",
      "test set score: 0.96\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#calculate time and accuracy for different number of features, using best parameters\n",
    "\n",
    "Nmax = [10, 100, 500, 1000, 5000, 12500]\n",
    "for i in Nmax:\n",
    "    start = time()\n",
    "    \n",
    "    cats_features = [get_features(get_image(img)).ravel() for img in cats_imgs[:i]]\n",
    "    dogs_features = [get_features(get_image(img)).ravel() for img in dogs_imgs[:i]]\n",
    "\n",
    "    Y_cats = np.array(i * [1])\n",
    "    Y_dogs = np.array(i * [0])\n",
    "\n",
    "    X_cvd = np.vstack([cats_features,dogs_features])\n",
    "    Y_cvd = np.vstack([Y_cats,Y_dogs]).ravel()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_cvd, Y_cvd, random_state=42)\n",
    "    \n",
    "    lg = LogisticRegression(**grid_search.best_params_, max_iter=3000).fit(X_train, y_train)\n",
    "    print(str(i)+' features:')\n",
    "    print(f'runtime {time() - start:.0f} seconds')\n",
    "    print('test set score: {:.2f}'.format(lg.score(X_test, y_test)))\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2 (5 points):\n",
    "\n",
    "Repeat all previous steps using MobileNet V2 (https://github.com/KeyKy/mobilenet-mxnet). How the two networks compare in terms of accuracy and running time?\n",
    "\n",
    "**WARNING**: At least for N= 5000 and 12500 it can take some time in your computer, depending of your resources. The time can largely increases depending of your chosen classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mobilenet_v2-symbol.json', 'mobilenet_v2-0000.params']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path='https://github.com/KeyKy/mobilenet-mxnet/'\n",
    "[mx.test_utils.download(path+'raw/master/mobilenet_v2-symbol.json'),\n",
    " mx.test_utils.download(path+'raw/master/mobilenet_v2-0000.params')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"nodes\": [\n",
      "{\n",
      "\"op\": \"null\",\n",
      "\"name\": \"data\",\n",
      "\"inputs\": []\n",
      "},\n",
      "{\n",
      "\"op\": \"null\",\n",
      "\"name\": \"conv1_weight\",\n"
     ]
    }
   ],
   "source": [
    "with open('mobilenet_v2-symbol.json', 'r') as f:\n",
    "    for n in range (10):\n",
    "        s = f.readline().strip()\n",
    "        if s: print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change manually the output layer to 'fc7_flatten_output' in .json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym, arg_params, aux_params = mx.model.load_checkpoint('mobilenet_v2', 0)\n",
    "mod = mx.mod.Module(symbol=sym, context=mx.cpu(), label_names=None)\n",
    "mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))], \n",
    "         label_shapes=mod._label_shapes)\n",
    "mod.set_params(arg_params, aux_params, allow_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv6_4_bn_moving_var',\n",
       " 'conv6_4_bn_output',\n",
       " 'relu6_4_output',\n",
       " 'pool6_output',\n",
       " 'fc7_weight',\n",
       " 'fc7_bias',\n",
       " 'fc7_output',\n",
       " 'fc7_flatten_output',\n",
       " 'prob_label',\n",
       " 'prob_output']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_layers = sym.get_internals()\n",
    "all_layers.list_outputs()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_sym = all_layers['fc7_flatten_output']\n",
    "fe_mod = mx.mod.Module(symbol=fe_sym, context=mx.cpu(), label_names=None)\n",
    "fe_mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))])\n",
    "fe_mod.set_params(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(img):\n",
    "    fe_mod.forward(Batch([mx.nd.array(img)]))\n",
    "    features = fe_mod.get_outputs()[0].asnumpy()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmax = 10\n",
    "cats_features = [get_features(get_image(img)).ravel() for img in cats_imgs[:Nmax]]\n",
    "dogs_features = [get_features(get_image(img)).ravel() for img in dogs_imgs[:Nmax]]\n",
    "\n",
    "Y_cats = np.array(Nmax * [1])\n",
    "Y_dogs = np.array(Nmax * [0])\n",
    "\n",
    "X_cvd = np.vstack([cats_features,dogs_features])\n",
    "Y_cvd = np.vstack([Y_cats,Y_dogs]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.20\n",
      "Best parameters: {'C': 0.1, 'multi_class': 'auto', 'solver': 'liblinear', 'tol': 0.01}\n",
      "Best cross-validation score: 0.67\n",
      "\n",
      "Best estimator:\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=3000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.01, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'tol': [0.0001,0.001,0.01,0.1,1],\n",
    "              'C': [0.1,1,10,50],\n",
    "              'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "              'multi_class': ['auto', 'ovr', 'multinomial']}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=3000), param_grid, cv=5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cvd, Y_cvd, random_state=42)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Test set score: {:.2f}\".format(grid_search.score(X_test, y_test)))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\\n\".format(grid_search.best_score_))\n",
    "print(\"Best estimator:\\n{}\".format(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 features:\n",
      "runtime 1 seconds\n",
      "test set score: 0.20\n",
      "--------------------\n",
      "100 features:\n",
      "runtime 13 seconds\n",
      "test set score: 0.48\n",
      "--------------------\n",
      "500 features:\n",
      "runtime 68 seconds\n",
      "test set score: 0.62\n",
      "--------------------\n",
      "1000 features:\n",
      "runtime 128 seconds\n",
      "test set score: 0.67\n",
      "--------------------\n",
      "5000 features:\n",
      "runtime 657 seconds\n",
      "test set score: 0.68\n",
      "--------------------\n",
      "12500 features:\n",
      "runtime 1746 seconds\n",
      "test set score: 0.69\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#calculate time and accuracy for different number of features and best params\n",
    "\n",
    "Nmax = [10, 100, 500, 1000, 5000, 12500]\n",
    "for i in Nmax:\n",
    "    start = time()\n",
    "    \n",
    "    cats_features = [get_features(get_image(img)).ravel() for img in cats_imgs[:i]]\n",
    "    dogs_features = [get_features(get_image(img)).ravel() for img in dogs_imgs[:i]]\n",
    "\n",
    "    Y_cats = np.array(i * [1])\n",
    "    Y_dogs = np.array(i * [0])\n",
    "\n",
    "    X_cvd = np.vstack([cats_features,dogs_features])\n",
    "    Y_cvd = np.vstack([Y_cats,Y_dogs]).ravel()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_cvd, Y_cvd, random_state=42)\n",
    "    \n",
    "    lg = LogisticRegression(**grid_search.best_params_, max_iter=3000).fit(X_train, y_train)\n",
    "    print(str(i)+' features:')\n",
    "    print(f'runtime {time() - start:.0f} seconds')\n",
    "    print('test set score: {:.2f}'.format(lg.score(X_test, y_test)))\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
